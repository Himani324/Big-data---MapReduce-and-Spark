{"cells":[{"cell_type":"markdown","metadata":{"id":"YRWMaqKqXYy0"},"source":["Himani Parikh - 1322085\n","\n","CSCI 636 - Big Data Analytics\n","\n","Hands on 12.1 : Weather\tPattern\tClustering using k-mean in Spark\n","Learning\tGoals"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":41268,"status":"ok","timestamp":1701979025204,"user":{"displayName":"Himani Parikh","userId":"02981417218218037925"},"user_tz":300},"id":"VJ4bse5YiqXi","outputId":"682eea77-470a-4505-ff80-8afb87121666"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyspark\n","  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n","Building wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hcanceled\n","\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n","\u001b[0mTraceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n","    status = run_func(*args)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 242, in wrapper\n","    return func(self, options, args)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 417, in run\n","    _, build_failures = build(\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/wheel_builder.py\", line 320, in build\n","    wheel_file = _build_one(\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/wheel_builder.py\", line 194, in _build_one\n","    wheel_path = _build_one_inside_env(\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/wheel_builder.py\", line 241, in _build_one_inside_env\n","    wheel_path = build_wheel_legacy(\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/build/wheel_legacy.py\", line 83, in build_wheel_legacy\n","    output = call_subprocess(\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/subprocess.py\", line 166, in call_subprocess\n","    line: str = proc.stdout.readline()\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/pip3\", line 8, in <module>\n","    sys.exit(main())\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 79, in main\n","    return command.main(cmd_args)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n","    return self._main(args)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n","    return run(options, args)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 206, in exc_logging_wrapper\n","    logger.critical(\"Operation cancelled by user\")\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1524, in critical\n","    self._log(CRITICAL, msg, args, **kwargs)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n","    self.handle(record)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n","    self.callHandlers(record)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n","    hdlr.handle(record)\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\n","    self.emit(record)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 177, in emit\n","    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/console.py\", line 1671, in print\n","    with self:\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/console.py\", line 864, in __exit__\n","    self._exit_buffer()\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/console.py\", line 822, in _exit_buffer\n","    self._check_buffer()\n","  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/console.py\", line 2060, in _check_buffer\n","    self.file.write(text)\n","KeyboardInterrupt\n","^C\n"]}],"source":["!pip install pyspark"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":818,"status":"error","timestamp":1701979026014,"user":{"displayName":"Himani Parikh","userId":"02981417218218037925"},"user_tz":300},"id":"Q2Vk_QmIi2MG","colab":{"base_uri":"https://localhost:8080/","height":393},"outputId":"06c66841-6640-4d0e-9821-408110093114"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-9eb60b818c2c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mspark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["from pyspark import SparkContext\n","from pyspark.sql import SparkSession\n","\n","spark = SparkSession\\\n","        .builder\\\n","        .master('local[*]')\\\n","        .getOrCreate()\n","sc = spark.sparkContext"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WU57lbFqjAH8","executionInfo":{"status":"aborted","timestamp":1701979026015,"user_tz":300,"elapsed":7,"user":{"displayName":"Himani Parikh","userId":"02981417218218037925"}}},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i8Qg9OpOvCq2","executionInfo":{"status":"aborted","timestamp":1701979026015,"user_tz":300,"elapsed":6,"user":{"displayName":"Himani Parikh","userId":"02981417218218037925"}}},"outputs":[],"source":["# change the directory to big-data-colab folder\n","%cd /content/drive/My Drive/Colab Notebooks/BigDataColabHimaniParikh/\n","\n","#pwd\n","!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PwiHKrfexP_P","executionInfo":{"status":"aborted","timestamp":1701979026016,"user_tz":300,"elapsed":7,"user":{"displayName":"Himani Parikh","userId":"02981417218218037925"}}},"outputs":[],"source":["# change the directory to big-data-colab folder\n","%cd /content/drive/My Drive/Colab Notebooks/BigDataColabHimaniParikh/Data-Cluster\n","\n","#pwd\n","!ls"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GYgli58TxTxM","executionInfo":{"status":"aborted","timestamp":1701979026016,"user_tz":300,"elapsed":7,"user":{"displayName":"Himani Parikh","userId":"02981417218218037925"}}},"outputs":[],"source":["!cp utils.py /content/utils.py"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ssRd3324xyiH","executionInfo":{"status":"aborted","timestamp":1701979026016,"user_tz":300,"elapsed":7,"user":{"displayName":"Himani Parikh","userId":"02981417218218037925"}}},"outputs":[],"source":["from pyspark.sql import SQLContext\n","from pyspark.sql import DataFrameNaFunctions\n","\n","from pyspark.ml.clustering import KMeans\n","from pyspark.ml.feature import VectorAssembler, StandardScaler\n","import utils\n","\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7UBMH0IiyX0f","executionInfo":{"status":"aborted","timestamp":1701979026016,"user_tz":300,"elapsed":7,"user":{"displayName":"Himani Parikh","userId":"02981417218218037925"}}},"outputs":[],"source":["sqlsc = SQLContext(sc)\n","\n","df = sqlsc.read.load('/content/drive/My Drive/Colab Notebooks/BigDataColabHimaniParikh/Data-Cluster/minute_weather.csv',\n","                     format='com.databricks.spark.csv',\n","                     header='true',\n","                     inferSchema='true')\n"]},{"cell_type":"markdown","metadata":{"id":"aFqUk092LnhI"},"source":["***Subset and remove unused data***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PKxIUYhQyhWX","executionInfo":{"status":"aborted","timestamp":1701979026016,"user_tz":300,"elapsed":7,"user":{"displayName":"Himani Parikh","userId":"02981417218218037925"}}},"outputs":[],"source":["df.count()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nxE6SNmykthN","executionInfo":{"status":"aborted","timestamp":1701979026016,"user_tz":300,"elapsed":7,"user":{"displayName":"Himani Parikh","userId":"02981417218218037925"}}},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"zAZu438JkrXT"},"source":["***Question 1.***\n","\n","---\n","\n","\n","\n","What percentage of samples have 0 for rain_accumulation?\n","\n","A. 157812 / 158726 = 99.4%\n","\n","B. 157237 / 158726 = 99.1%\n","\n","C. There is not enough information to determine this D. None of the above\n","\n","ANS: A"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UGrEU9JqyxAY","executionInfo":{"status":"aborted","timestamp":1701979026016,"user_tz":300,"elapsed":7,"user":{"displayName":"Himani Parikh","userId":"02981417218218037925"}}},"outputs":[],"source":["filteredDf = df.filter((df.rowID % 5) == 0) # 10th, 2oth, 30th\n","filteredDf.count()"]},{"cell_type":"markdown","metadata":{"id":"LyLd6S44d5AC"},"source":["***Q3***\n","\n","\n","---\n","\n","\n","If we wanted to create a data subset by taking every 5th sample instead of every 10th sample, how many samples would be in that subset?\n","\n","A. 317,452\n","\n","B. 1,587,257\n","\n","C. 158,726\n","\n","D. None of the above\n","\n","ANS: A\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mt7X8UAYzH1k","executionInfo":{"status":"aborted","timestamp":1701979026016,"user_tz":300,"elapsed":7,"user":{"displayName":"Himani Parikh","userId":"02981417218218037925"}}},"outputs":[],"source":["filteredDf.describe().toPandas().transpose()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8wUWqZGmzQOX","executionInfo":{"status":"aborted","timestamp":1701979026016,"user_tz":300,"elapsed":6,"user":{"displayName":"Himani Parikh","userId":"02981417218218037925"}}},"outputs":[],"source":["filteredDf.filter(filteredDf.rain_accumulation == 0.0).count()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wmziiWwKzbyI","executionInfo":{"status":"aborted","timestamp":1701979026016,"user_tz":300,"elapsed":6,"user":{"displayName":"Himani Parikh","userId":"02981417218218037925"}}},"outputs":[],"source":["filteredDf.filter(filteredDf.rain_duration == 0.0).count()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VBqBJfwBzfPc","executionInfo":{"status":"aborted","timestamp":1701979026016,"user_tz":300,"elapsed":6,"user":{"displayName":"Himani Parikh","userId":"02981417218218037925"}}},"outputs":[],"source":["workingDf = filteredDf.drop(\"rain_accumulation\").drop(\"rain_duration\"). drop(\"hpwren_timestamp\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sB6YNanwz1O5","executionInfo":{"status":"aborted","timestamp":1701979026016,"user_tz":300,"elapsed":6,"user":{"displayName":"Himani Parikh","userId":"02981417218218037925"}}},"outputs":[],"source":["before = workingDf.count()\n","workingDf = workingDf.na.drop()\n","after = workingDf.count()\n","before - after"]},{"cell_type":"markdown","metadata":{"id":"XX1gd8gvL7VX"},"source":["***Scale the data***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n8s90rl_0FQp","executionInfo":{"status":"aborted","timestamp":1701979026016,"user_tz":300,"elapsed":6,"user":{"displayName":"Himani Parikh","userId":"02981417218218037925"}}},"outputs":[],"source":["workingDf.columns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x6K15dIr0PlI","executionInfo":{"status":"aborted","timestamp":1701979026016,"user_tz":300,"elapsed":6,"user":{"displayName":"Himani Parikh","userId":"02981417218218037925"}}},"outputs":[],"source":["featuresUsed = [\n"," 'air_pressure',\n"," 'air_temp',\n"," 'avg_wind_direction',\n"," 'avg_wind_speed',\n"," 'max_wind_direction',\n"," 'max_wind_speed',\n"," 'relative_humidity']\n","\n","assembler = VectorAssembler(inputCols=featuresUsed, outputCol=\"features_unscaled\")\n","assembled = assembler.transform(workingDf)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i042HL_O0rQN","executionInfo":{"status":"aborted","timestamp":1701979026016,"user_tz":300,"elapsed":6,"user":{"displayName":"Himani Parikh","userId":"02981417218218037925"}}},"outputs":[],"source":["scaler = StandardScaler(inputCol=\"features_unscaled\", outputCol=\"features\", withStd=True, withMean=True)\n","scalerModel = scaler.fit(assembled)\n","scaledData = scalerModel.transform(assembled)"]},{"cell_type":"markdown","metadata":{"id":"M_n7p0CNL_7m"},"source":["***Create elbow plot***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eEBbclGj3hJA","executionInfo":{"status":"aborted","timestamp":1701979026017,"user_tz":300,"elapsed":7,"user":{"displayName":"Himani Parikh","userId":"02981417218218037925"}}},"outputs":[],"source":["scaledData = scaledData.select(\"features\", \"rowID\")\n","elbowset = scaledData.filter((scaledData.rowID % 3) == 0).select(\"features\")\n","elbowset.persist()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1TacDL3G792k","executionInfo":{"status":"aborted","timestamp":1701979026017,"user_tz":300,"elapsed":7,"user":{"displayName":"Himani Parikh","userId":"02981417218218037925"}}},"outputs":[],"source":["clusters = range(2,31)\n","wsseList = utils.elbow(elbowset, clusters)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cK4hiTxmLQL3","executionInfo":{"status":"aborted","timestamp":1701979026017,"user_tz":300,"elapsed":7,"user":{"displayName":"Himani Parikh","userId":"02981417218218037925"}}},"outputs":[],"source":["utils.elbow_plot(wsseList, clusters)"]},{"cell_type":"markdown","metadata":{"id":"Bh1coLwOLaRV"},"source":["***Cluster using selected K***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yaObwtbjMKdl","executionInfo":{"status":"aborted","timestamp":1701979026017,"user_tz":300,"elapsed":7,"user":{"displayName":"Himani Parikh","userId":"02981417218218037925"}}},"outputs":[],"source":["scaledDataFeat = scaledData.select(\"features\")\n","scaledDataFeat.persist()"]},{"cell_type":"markdown","metadata":{"id":"O7IcO9TyE4ln"},"source":["***Q7.***\n","\n","\n","---\n","\n","\n","If we perform clustering with 20 clusters (and seed = 1), which cluster appears to identify Santa Ana conditions (lowest humidity and highest wind speeds)?\n","\n","\n","\n","\n","A. Cluster 12\n","\n","B. Cluster 1\n","\n","C. Cluster 16\n","\n","D. None of the above\n","\n","ANS A"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sdw6pNAsMUr2","executionInfo":{"status":"aborted","timestamp":1701979026017,"user_tz":300,"elapsed":6,"user":{"displayName":"Himani Parikh","userId":"02981417218218037925"}}},"outputs":[],"source":["kmeans = KMeans(k=20, seed=1)\n","model = kmeans.fit(scaledDataFeat)\n","transformed = model.transform(scaledDataFeat)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zYoqp1QSMtpV","executionInfo":{"status":"aborted","timestamp":1701979026017,"user_tz":300,"elapsed":6,"user":{"displayName":"Himani Parikh","userId":"02981417218218037925"}}},"outputs":[],"source":["centers = model.clusterCenters()\n","centers"]},{"cell_type":"markdown","metadata":{"id":"sK8E7KldMzfV"},"source":["***Create parallel plots of clusters and analysis***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"unLCKuX8M5jh","executionInfo":{"status":"aborted","timestamp":1701979026017,"user_tz":300,"elapsed":6,"user":{"displayName":"Himani Parikh","userId":"02981417218218037925"}}},"outputs":[],"source":["P = utils.pd_centers(featuresUsed, centers)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u6noIJxENBs2","executionInfo":{"status":"aborted","timestamp":1701979026017,"user_tz":300,"elapsed":6,"user":{"displayName":"Himani Parikh","userId":"02981417218218037925"}}},"outputs":[],"source":["utils.parallel_plot(P[P['relative_humidity'] < -0.5], P)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BP6RQRDSNXAd","executionInfo":{"status":"aborted","timestamp":1701979026017,"user_tz":300,"elapsed":6,"user":{"displayName":"Himani Parikh","userId":"02981417218218037925"}}},"outputs":[],"source":["utils.parallel_plot(P[P['air_temp'] > 0.5], P)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J44fb3jqNooc","executionInfo":{"status":"aborted","timestamp":1701979026017,"user_tz":300,"elapsed":6,"user":{"displayName":"Himani Parikh","userId":"02981417218218037925"}}},"outputs":[],"source":["utils.parallel_plot(P[(P['relative_humidity'] > 0.5) & (P['air_temp'] < 0.5)] , P)"]},{"cell_type":"markdown","metadata":{"id":"AokXqYCBOLVx"},"source":["***Other days***"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aOMluDzWONem","executionInfo":{"status":"aborted","timestamp":1701979026017,"user_tz":300,"elapsed":6,"user":{"displayName":"Himani Parikh","userId":"02981417218218037925"}}},"outputs":[],"source":["utils.parallel_plot(P.iloc[[1,3]], P)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"obddpWyOhonZ","executionInfo":{"status":"aborted","timestamp":1701979026017,"user_tz":300,"elapsed":6,"user":{"displayName":"Himani Parikh","userId":"02981417218218037925"}}},"outputs":[],"source":["utils.parallel_plot(P.iloc[[7,8,11]], P)"]},{"cell_type":"markdown","metadata":{"id":"cS3vIzueFMD6"},"source":["***Q8.***\n","\n","\n","\n","---\n","\n","\n","We did not include the minimum wind measurements in the analysis since they are highly correlated with the average wind measurements. What is the correlation between min_wind_speed and avg_wind_speed (to two decimals)? (Compute this using one-tenth of the original dataset, and dropping all rows with missing values.)\n","\n","A. 0.97\n","\n","B. -0.12\n","\n","C. 0.62\n","\n","D. None of the above\n","\n","ANS: A"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3VVRw4KQF9yG","executionInfo":{"status":"aborted","timestamp":1701979026017,"user_tz":300,"elapsed":6,"user":{"displayName":"Himani Parikh","userId":"02981417218218037925"}}},"outputs":[],"source":["filteredDf = df.filter((df.rowID % 10) == 0) # 10th, 2oth, 30th\n","filteredDf.count()\n","\n","\n","filteredDf.describe().toPandas().transpose()\n","\n","filteredDf.filter(filteredDf.rain_accumulation == 0.0).count()\n","\n","filteredDf.filter(filteredDf.rain_duration == 0.0).count()\n","\n","workingDf = filteredDf.drop(\"rain_accumulation\").drop(\"rain_duration\"). drop(\"hpwren_timestamp\")\n","\n","before = workingDf.count()\n","workingDf = workingDf.na.drop()\n","after = workingDf.count()\n","before - after\n","\n","\n","workingDf.columns\n","\n","featuresUsed = [\n"," 'air_pressure',\n"," 'air_temp',\n"," 'avg_wind_direction',\n"," 'avg_wind_speed',\n"," 'max_wind_direction',\n"," 'max_wind_speed',\n"," 'relative_humidity']\n","\n","assembler = VectorAssembler(inputCols=featuresUsed, outputCol=\"features_unscaled\")\n","assembled = assembler.transform(workingDf)\n","\n","scaler = StandardScaler(inputCol=\"features_unscaled\", outputCol=\"features\", withStd=True, withMean=True)\n","scalerModel = scaler.fit(assembled)\n","scaledData = scalerModel.transform(assembled)\n","\n","\n","scaledData = scaledData.select(\"features\", \"rowID\")\n","elbowset = scaledData.filter((scaledData.rowID % 3) == 0).select(\"features\")\n","elbowset.persist()\n","\n","clusters = range(2,31)\n","wsseList = utils.elbow(elbowset, clusters)\n","\n","utils.elbow_plot(wsseList, clusters)\n","\n","\n","scaledDataFeat = scaledData.select(\"features\")\n","scaledDataFeat.persist()\n","\n","\n","\n","\n","P = utils.pd_centers(featuresUsed, centers)\n","\n","utils.parallel_plot(P[P['relative_humidity'] < -0.5], P)\n","\n","utils.parallel_plot(P[P['air_temp'] > 0.5], P)\n","\n","utils.parallel_plot(P[(P['relative_humidity'] > 0.5) & (P['air_temp'] < 0.5)] , P)\n","\n","\n","utils.parallel_plot(P.iloc[[1,3]], P)\n","\n","utils.parallel_plot(P.iloc[[7,8,11]], P)\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"1CocdXaw2s5VI09UnPlIXFhkXLkTpF3Ab","timestamp":1701887881212}],"authorship_tag":"ABX9TyNoLrRi7E+9WRPz90QlpAQU"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}